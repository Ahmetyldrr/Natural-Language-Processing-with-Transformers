# Makine Zekası ve Doğal Dil İşleme (NLP) Hakkında Açıklamalar

Makine zekası, tahminler yapmak için insanlarla aynı verileri kullanır. (Doğru/Yanlış) Doğru ve yanlış. Doğru çünkü bazı durumlarda, makine zekası, anlam çıkarmak ve insanlar için yüzyıllar sürecek çeşitli görevleri gerçekleştirmek için büyük miktarda veriyi işlerken insanları aşar. Yanlış çünkü, Doğal Dil Anlama (NLU) için, insanların duyuları aracılığıyla daha fazla bilgiye erişimi vardır. Makine zekası, her türlü medya açısından insanların sağladıklarına güvenmektedir.

# SuperGLUE ve GLUE Karşılaştırması

SuperGLUE, NLP modelleri için GLUE'den daha zordur. (Doğru/Yanlış) Doğru.

# BoolQ ve WiC Hakkında

BoolQ, ikili bir cevap bekler. (Doğru/Yanlış) Doğru. WiC, Bağlamdaki Kelimeler anlamına gelir. (Doğru/Yanlış) Doğru.

# Metinsel İçerme Tanıma (RTE) ve Winograd Şemaları

Metinsel İçerme Tanıma (RTE), bir dizinin başka bir diziyi içerip içermediğini algılar. (Doğru/Yanlış) Doğru. Winograd şeması, bir fiilin doğru yazılışını tahmin eder. (Doğru/Yanlış) Yanlış. Winograd şemaları esas olarak zamir belirsizliğini gidermeye uygulanır.

# Transformer Modeller ve Başarıları

Transformer modelleri şimdi GLUE ve SuperGLUE'nin üst sıralarını işgal ediyor. (Doğru/Yanlış) Doğru. İnsan Referans Standartları bir kez ve herkes için tanımlanmamıştır. SuperGLUE tarafından ulaşılması daha zor hale getirildi. (Doğru/Yanlış) Doğru.

# Gelecek Tahminleri

Transformer modelleri asla SuperGLUE insan referans standartlarını geçemeyecek. (Doğru/Yanlış) Doğru ve yanlış. Yanlış çünkü transformer modelleri GLUE için insan referanslarını aştı ve gelecekte SuperGLUE için de aynı şeyi yapacak. Doğru çünkü NLU alanında ilerledikçe daha yüksek ölçüt standartları belirlemeye devam edeceğiz. Transformer modellerinin varyantları, RNN ve CNN modellerini geride bıraktı. (Doğru/Yanlış) Doğru. Ancak AI'nın geleceği hakkında asla bilemezsiniz!

Bu çeviride herhangi bir python kodu bulunmamaktadır.

---

