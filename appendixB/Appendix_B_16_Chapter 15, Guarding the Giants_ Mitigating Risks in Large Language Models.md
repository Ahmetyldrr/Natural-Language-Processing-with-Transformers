# Doğru mu Yanlış mı: ChatGPT ve Yapay Zeka ile İlgili Sorular ve Yanıtlar

Aşağıda verilen İngilizce paragrafın birebir Türkçe çevirisi yapılmıştır.

İngilizce paragraf:
```
It’s impossible to force ChatGPT to harass somebody. (True/False) False. ChatGPT can be unknowingly led to harmful conduct. We need to be on alert. Hallucinations are only for humans. (True/False) False. AI can hallucinate as well when it generates random content unrelated to the prompt. Privacy is taken seriously on the leading cloud platforms. (True/False) True. Platforms are making significant progress under the pressure of increasing regulations and building trustworthy services. But we must always read the privacy policies. APIs pose no risk. (True/False) False. We need to verify the encryption used. Harmful content can be filtered. (True/False) True and false. We can reduce harmful content with a solid rule base and the moderation models available. A moderation model is 100% reliable. (True/False) False. We need to enforce the system with rule bases and verify the data used by models. A rule base is useless when using LLMs. (True/False) True and false. This will depend on the goals of the project. A knowledge base will make the transformer ecosystem more reliable. (True/False) True and false. A solid knowledge base can improve the quality of a system. However, this depends on each project. We cannot add information to a prompt. (True/False) False. We can add parameters. And in ChatGPT models, we can add informative messages. Prompt engineering requires more effort than prompt design. (True/False) True. No particular machine learning knowledge is required for prompt design. However, advanced prompt engineering requires machine learning expertise, such as adding moderation tools, knowledge bases, and other functions.
```

Türkçe çevirisi:
```
ChatGPT'yi birini taciz etmeye zorlamak imkansızdır. (Doğru/Yanlış) Yanlış. ChatGPT bilmeden zararlı davranışlara yönlendirilebilir. Uyanık olmamız gerekir. Halüsinasyonlar sadece insanlara özgüdür. (Doğru/Yanlış) Yanlış. Yapay zeka da istem ile ilgili olmayan rastgele içerik ürettiğinde halüsinasyonlar yaşayabilir. Gizlilik önde gelen bulut platformlarında ciddiye alınır. (Doğru/Yanlış) Doğru. Platformlar artan düzenlemelerin baskısı altında önemli ilerlemeler kaydediyor ve güvenilir hizmetler inşa ediyor. Ancak her zaman gizlilik politikalarını okumalıyız. API'ler risk oluşturmaz. (Doğru/Yanlış) Yanlış. Kullanılan şifrelemeyi doğrulamamız gerekir. Zararlı içerik filtrelenebilir. (Doğru/Yanlış) Doğru ve yanlış. Sağlam bir kural tabanı ve mevcut moderasyon modelleri ile zararlı içerikleri azaltabiliriz. Bir moderasyon modeli %100 güvenilirdir. (Doğru/Yanlış) Yanlış. Sistemi kural tabanları ile güçlendirmeli ve modeller tarafından kullanılan verileri doğrulamalıyız. LLMs kullanırken bir kural tabanı işe yaramaz. (Doğru/Yanlış) Doğru ve yanlış. Bu, projenin hedeflerine bağlıdır. Bir bilgi tabanı, transformer ekosistemini daha güvenilir hale getirecektir. (Doğru/Yanlış) Doğru ve yanlış. Sağlam bir bilgi tabanı bir sistemin kalitesini artırabilir. Ancak bu, her projeye bağlıdır. Bir isteme bilgi ekleyemeyiz. (Doğru/Yanlış) Yanlış. Parametreler ekleyebiliriz. Ve ChatGPT modellerinde bilgilendirici mesajlar ekleyebiliriz. Prompt mühendisliği, prompt tasarımından daha fazla çaba gerektirir. (Doğru/Yanlış) Doğru. Prompt tasarımı için özel makine öğrenimi bilgisi gerekmez. Ancak gelişmiş prompt mühendisliği, moderasyon araçları, bilgi tabanları ve diğer işlevler eklemek gibi makine öğrenimi uzmanlığı gerektirir.
```

Paragrafta Python kodları bulunmamaktadır. Sadece Doğru/Yanlış soruları ve yanıtları ile ilgili açıklamalar vardır.

## Doğru/Yanlış Soruları ve Yanıtları

1. **ChatGPT'yi birini taciz etmeye zorlamak imkansızdır.** (Doğru/Yanlış) **Yanlış**. ChatGPT bilmeden zararlı davranışlara yönlendirilebilir.
2. **Halüsinasyonlar sadece insanlara özgüdür.** (Doğru/Yanlış) **Yanlış**. Yapay zeka da istem ile ilgili olmayan rastgele içerik ürettiğinde halüsinasyonlar yaşayabilir.
3. **Gizlilik önde gelen bulut platformlarında ciddiye alınır.** (Doğru/Yanlış) **Doğru**. Platformlar artan düzenlemelerin baskısı altında önemli ilerlemeler kaydediyor ve güvenilir hizmetler inşa ediyor.
4. **API'ler risk oluşturmaz.** (Doğru/Yanlış) **Yanlış**. Kullanılan şifrelemeyi doğrulamamız gerekir.
5. **Zararlı içerik filtrelenebilir.** (Doğru/Yanlış) **Doğru ve yanlış**. Sağlam bir kural tabanı ve mevcut moderasyon modelleri ile zararlı içerikleri azaltabiliriz.
6. **Bir moderasyon modeli %100 güvenilirdir.** (Doğru/Yanlış) **Yanlış**. Sistemi kural tabanları ile güçlendirmeli ve modeller tarafından kullanılan verileri doğrulamalıyız.
7. **LLMs kullanırken bir kural tabanı işe yaramaz.** (Doğru/Yanlış) **Doğru ve yanlış**. Bu, projenin hedeflerine bağlıdır.
8. **Bir bilgi tabanı, transformer ekosistemini daha güvenilir hale getirecektir.** (Doğru/Yanlış) **Doğru ve yanlış**. Sağlam bir bilgi tabanı bir sistemin kalitesini artırabilir. Ancak bu, her projeye bağlıdır.
9. **Bir isteme bilgi ekleyemeyiz.** (Doğru/Yanlış) **Yanlış**. Parametreler ekleyebiliriz. Ve ChatGPT modellerinde bilgilendirici mesajlar ekleyebiliriz.
10. **Prompt mühendisliği, prompt tasarımından daha fazla çaba gerektirir.** (Doğru/Yanlış) **Doğru**. Prompt tasarımı için özel makine öğrenimi bilgisi gerekmez. Ancak gelişmiş prompt mühendisliği, moderasyon araçları, bilgi tabanları ve diğer işlevler eklemek gibi makine öğrenimi uzmanlığı gerektirir.

---

