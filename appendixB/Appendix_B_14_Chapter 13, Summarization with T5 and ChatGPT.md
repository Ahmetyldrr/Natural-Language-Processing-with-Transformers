# T5 ve Text-to-Text Modelleri Hakkında Doğru/Yanlış Soruları

Aşağıda verilen İngilizce paragrafın birebir Türkçe çevirisi yapılmıştır.

T5 modelleri sadece BERT modelleri gibi kodlayıcı (encoder) yığınlarına sahiptir. (Doğru/Yanlış) Yanlış. T5 modelleri hem kodlayıcı (encoder) hem de çözücü (decoder) yığınlarına sahiptir. (Doğru/Yanlış) Doğru. T5 modelleri mutlak pozisyonel kodlama yerine göreli pozisyonel kodlama kullanır. (Doğru/Yanlış) Doğru. Metin-metin (text-to-text) modelleri sadece özetleme için tasarlanmıştır. (Doğru/Yanlış) Yanlış. Metin-metin modelleri, NLP görevini belirleyen bir önek (prefix) giriş sırasına uygular. (Doğru/Yanlış) Doğru. T5 modelleri her görev için özel hiperparametreler gerektirir. (Doğru/Yanlış) Yanlış. Metin-metin modellerinin avantajlarından biri, tüm NLP görevleri için aynı hiperparametreleri kullanmasıdır. (Doğru/Yanlış) Doğru. T5 transformer'ları bir ileri beslemeli ağ (feedforward network) içermez. (Doğru/Yanlış) Yanlış. Hugging Face, transformer'ları uygulamasını kolaylaştıran bir çerçevedir. (Doğru/Yanlış) Doğru. OpenAI'ın transformer'ları özetleme görevleri için en iyisidir. (Doğru/Yanlış) Doğru ve yanlış. Genel olarak metinleri özetlemek için doğrudur. Yanlıştır çünkü bazı durumlarda, T5 gibi göreve özgü bir özetleme transformer'ı özel bir alanda daha iyi çıktılar sağlayabilir.

Bu çeviride herhangi bir Python kodu bulunmamaktadır.

---

