# O(1) Notasyonu ve Dikkat Katmanı

O(1) bir "Big O" notasyonudur. "Big O" "mertebesi" veya "düzeni" anlamına gelir. Bu durumda, O(1) sabit bir zaman karmaşıklığını temsil eder. O(1) veya 1 işlem sırası diyebiliriz. İster inanın ister inanmayın, devrimin kalbinde yer alıyorsunuz! 
Dikkatimizi, transformerlar ve ChatGPT çılgınlığı yoluyla yapay zeka'nın endüstrileşmesine yol açan şeye odaklayalım: 
öz-dikkat ile donanım verimliliğinin üstel artışı. Dikkatin donanımı nasıl kullandığını ve makine öğreniminin inanılmaz yeni yollarının kapısını nasıl açtığını keşfedeceğiz.

Aşağıdaki cümle 11 kelime içermektedir: Jay portakalları sabahları sever ama akşamları sevmez. 
Cümlenin uzunluğu n = 11'dir. 
Dil anlama problemi tek kelimeyle özetlenebilir: bağlam. 
Bir kelime nadiren bağlam olmadan tanımlanabilir. 
Bir kelimenin anlamı, bir sözlükteki tanımının ötesinde her bağlamda değişebilir. 
Dikkat katmanına kavramsal bir yaklaşımla başlayalım.

Python kodu bulunmamaktadır, sadece bir ingilizce paragrafın türkçeye birebir çevirisi yapılmıştır. 

Eğer bir python kodu olsaydı, satır satır açıklama aşağıdaki gibi olurdu:
```python
# örnek python kodu
def attention_layer(input):
    # burada dikkat katmanı implementasyonu yapılır
    pass

# cümlenin uzunluğunu hesaplama
sentence = "Jay likes oranges in the morning but not in the evening"
n = len(sentence.split())  # n = 11
print(n)
```
Bu kodda:
- `attention_layer` fonksiyonu tanımlanmıştır, ancak içi boş bırakılmıştır.
- `sentence` değişkenine bir cümle atanmıştır.
- `n` değişkenine cümlenin kelime sayısı atanmıştır. (`split()` fonksiyonu cümleyi kelimelere ayırır)

---

